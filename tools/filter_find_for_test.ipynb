{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Coding/CVPR2025_abaw_framewise/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7250\n",
      "Optimal window size: 60\n",
      "Maximized F1-Score: 0.7279\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "res_path = \"/Coding/CVPR2025_abaw_framewise/tools/output/0-7197-ep5.txt\"\n",
    "eval_path = \"/Coding/CVPR2025_abaw_framewise/data_abaw/splits/val_relaxed.csv\"\n",
    "\n",
    "\n",
    "\n",
    "eval_df = pd.read_csv(eval_path)\n",
    "res = pd.read_csv(res_path , names=[\"1\",\"2\",\"class_id\",\"general_path\"], sep=\",\", header=None)\n",
    "\n",
    "true_labels = eval_df['class_id']\n",
    "scores = res['class_id']\n",
    "\n",
    "threshold = 0.577\n",
    "\n",
    "average = \"weighted\"\n",
    "\n",
    "predicted_labels = (scores > threshold).astype(int)\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Moving average smoothing filter function\n",
    "def moving_average_filter(data, window_size):\n",
    "    # Ensure data is a numpy array of floats\n",
    "    data = np.array(data, dtype=float)\n",
    "    kernel = np.ones(window_size, dtype=float) / window_size\n",
    "    return np.convolve(data, kernel, mode='same')\n",
    "\n",
    "# Initialize variables for optimization\n",
    "best_f1 = 0\n",
    "best_window = None\n",
    "\n",
    "# Loop over possible window sizes (1 to 20)\n",
    "for window in range(1, 200):\n",
    "    # Apply the smoothing filter with the current window size\n",
    "    smoothed_scores = moving_average_filter(scores, window)\n",
    "    \n",
    "    # Apply the fixed threshold to obtain binary predictions\n",
    "    predicted_labels = ((1)*smoothed_scores >= threshold).astype(int)\n",
    "    \n",
    "    # Compute the F1-score using the specified averaging method\n",
    "    current_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "    \n",
    "    # Update the best F1-score and corresponding window size if improvement is found\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_window = window\n",
    "\n",
    "# Apply the smoothing filter with the optimal window size for final predictions\n",
    "final_smoothed_scores = moving_average_filter(scores, best_window)\n",
    "final_predictions = (final_smoothed_scores >= threshold).astype(int)\n",
    "\n",
    "# Print the optimal window size and the maximized F1-score\n",
    "print(f\"Optimal window size: {best_window}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal sigma: 3.7999999999999994\n",
      "Maximized F1-Score: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# Gaussian smoothing filter function using scipy's gaussian_filter1d\n",
    "def gaussian_smoothing_filter(data, sigma):\n",
    "    return gaussian_filter1d(data.astype(float), sigma=sigma)\n",
    "\n",
    "# Initialize variables for parameter optimization\n",
    "best_f1 = 0\n",
    "best_sigma = None\n",
    "\n",
    "# Loop over possible sigma values (e.g., from 0.5 to 5.0 with step 0.5)\n",
    "for sigma in np.arange(0.5, 5.5, 0.1):\n",
    "    # Apply the Gaussian smoothing filter with the current sigma\n",
    "    smoothed_scores = gaussian_smoothing_filter(scores, sigma)\n",
    "    \n",
    "    # Apply the fixed threshold to obtain binary predictions\n",
    "    predicted_labels = (smoothed_scores >= threshold).astype(int)\n",
    "    \n",
    "    # Compute the F1-score using the specified averaging method\n",
    "    current_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "    \n",
    "    # Update the best F1-score and corresponding sigma if improvement is found\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_sigma = sigma\n",
    "\n",
    "# Apply the smoothing filter with the optimal sigma for final predictions\n",
    "final_smoothed_scores = gaussian_smoothing_filter(scores, best_sigma)\n",
    "final_predictions = (final_smoothed_scores >= threshold).astype(int)\n",
    "\n",
    "# Print the optimal sigma and the maximized F1-score\n",
    "print(f\"Optimal sigma: {best_sigma}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimaler Fenstergröße für uniform_filter1d: 45\n",
      "Maximierter F1-Score für uniform_filter1d: 0.7277\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Uniform Smoothing Filter Funktion\n",
    "def uniform_smoothing_filter(data, size):\n",
    "    return uniform_filter1d(data.astype(float), size=size)\n",
    "\n",
    "# Initialisierung der Variablen für die Optimierung\n",
    "best_f1_uniform = 0\n",
    "best_size_uniform = None\n",
    "\n",
    "# Schleife über mögliche Fenstergrößen (z. B. von 3 bis 51 in Schritten von 2)\n",
    "for size in range(3, 70, 2):\n",
    "    # Filterung der Scores mit der aktuellen Fenstergröße\n",
    "    smoothed_scores = uniform_smoothing_filter(scores, size)\n",
    "    \n",
    "    # Erzeugen der binären Vorhersagen basierend auf einem festen Schwellenwert\n",
    "    predicted_labels = (smoothed_scores >= threshold).astype(int)\n",
    "    \n",
    "    # Berechnung des F1-Scores\n",
    "    current_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "    \n",
    "    # Update der besten Parameter, falls eine Verbesserung erzielt wurde\n",
    "    if current_f1 > best_f1_uniform:\n",
    "        best_f1_uniform = current_f1\n",
    "        best_size_uniform = size\n",
    "\n",
    "# Ausgabe der optimalen Fenstergröße und des maximierten F1-Scores für uniform_filter1d\n",
    "print(f\"Optimaler Fenstergröße für uniform_filter1d: {best_size_uniform}\")\n",
    "print(f\"Maximierter F1-Score für uniform_filter1d: {best_f1_uniform:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimaler Fenstergröße für maximum_filter1d: 3\n",
      "Maximierter F1-Score für maximum_filter1d: 0.7242\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import maximum_filter1d\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Maximum Smoothing Filter Funktion\n",
    "def maximum_smoothing_filter(data, size):\n",
    "    return maximum_filter1d(data.astype(float), size=size)\n",
    "\n",
    "# Initialisierung der Variablen für die Optimierung\n",
    "best_f1_maximum = 0\n",
    "best_size_maximum = None\n",
    "\n",
    "# Schleife über mögliche Fenstergrößen (z. B. von 3 bis 51 in Schritten von 2)\n",
    "for size in range(3, 52, 2):\n",
    "    # Filterung der Scores mit der aktuellen Fenstergröße\n",
    "    smoothed_scores = maximum_smoothing_filter(scores, size)\n",
    "    \n",
    "    # Erzeugen der binären Vorhersagen basierend auf einem festen Schwellenwert\n",
    "    predicted_labels = (smoothed_scores >= threshold).astype(int)\n",
    "    \n",
    "    # Berechnung des F1-Scores\n",
    "    current_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "    \n",
    "    # Update der besten Parameter, falls eine Verbesserung erzielt wurde\n",
    "    if current_f1 > best_f1_maximum:\n",
    "        best_f1_maximum = current_f1\n",
    "        best_size_maximum = size\n",
    "\n",
    "# Ausgabe der optimalen Fenstergröße und des maximierten F1-Scores für maximum_filter1d\n",
    "print(f\"Optimaler Fenstergröße für maximum_filter1d: {best_size_maximum}\")\n",
    "print(f\"Maximierter F1-Score für maximum_filter1d: {best_f1_maximum:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "zeroes_to_fill: 1\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 2\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 3\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 4\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 5\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 6\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 7\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 8\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 9\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 10\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 11\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 12\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 13\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 14\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 15\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 16\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 17\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 18\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 19\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 20\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 21\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 22\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 23\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 24\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 25\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 26\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 27\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 28\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 29\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 30\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 31\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 32\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 33\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 34\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 35\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 36\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 37\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 38\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 39\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 40\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 41\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 42\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 43\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 44\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 45\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 46\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 47\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 48\n",
      "F1-Score: 0.7226\n",
      "zeroes_to_fill: 49\n",
      "F1-Score: 0.7226\n",
      "Optimal zeroes_to_fill: 0\n",
      "Maximized F1-Score: 0.7226\n"
     ]
    }
   ],
   "source": [
    "best_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "best_zeroes_to_fill = 0\n",
    "\n",
    "def optimize_zeroes_to_fill(res, zeroes_to_fill):\n",
    "    adjusted_predictions = predicted_labels.copy()\n",
    "    last_path = None\n",
    "    zero_count = 0\n",
    "\n",
    "    i = 0\n",
    "    n = len(res)\n",
    "    while i < n:\n",
    "        current_path = res[\"general_path\"].iloc[i]\n",
    "\n",
    "        if last_path != current_path:\n",
    "            zero_count = 0\n",
    "            last_path = current_path\n",
    "\n",
    "        if adjusted_predictions[i] == 0:\n",
    "            zero_count += 1\n",
    "\n",
    "        if adjusted_predictions[i] == 1:\n",
    "            if zero_count <= zeroes_to_fill:\n",
    "                start_index = i - zero_count  # first index of current zero sequence\n",
    "                \n",
    "                # Replace zeros after the allowed threshold in the current sequence\n",
    "                for k in range(start_index, i + 1):\n",
    "                    adjusted_predictions[k] = 1\n",
    "                \n",
    "                zero_count = 0\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return adjusted_predictions\n",
    "\n",
    "for zeroes in range(1, 50):  \n",
    "    new_predictions = optimize_zeroes_to_fill(res, zeroes)\n",
    "    current_f1 = f1_score(true_labels, new_predictions, average=average)\n",
    "\n",
    "    print(f\"zeroes_to_fill: {zeroes}\")\n",
    "    print(f\"F1-Score: {current_f1:.4f}\")\n",
    "\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_zeroes_to_fill = zeroes\n",
    "\n",
    "final_predictions = optimize_zeroes_to_fill(res, best_zeroes_to_fill)\n",
    "\n",
    "print(f\"Optimal zeroes_to_fill: {best_zeroes_to_fill}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "arr = [0,0,0,1,1,1,1,0,1,1,1,0,0,0,0,0,1,1,0,0,0,0]\n",
    "zeroes_to_fill = 3\n",
    "\n",
    "i = 0\n",
    "n = 10\n",
    "zero_count = 0\n",
    "while i < n:\n",
    "\n",
    "    if arr[i] == 0:\n",
    "        zero_count += 1\n",
    "\n",
    "    if arr[i] == 1:\n",
    "        if zero_count <= zeroes_to_fill:\n",
    "            start_index = i - zero_count   # first index of current zero sequence\n",
    "        \n",
    "            # Replace zeros after the allowed threshold in the current sequence\n",
    "            for k in range(start_index, i + 1):\n",
    "                arr[k] = 1\n",
    "\n",
    "        zero_count = 0\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7250388483323572\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zeroes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m):  \n\u001b[1;32m     42\u001b[0m     new_predictions, tresh \u001b[38;5;241m=\u001b[39m optimize_zeroes_to_fill(scores, res, zeroes, best_f1, best_thresh\u001b[38;5;241m=\u001b[39mbest_part_tresh, true_labels\u001b[38;5;241m=\u001b[39mtrue_labels)\n\u001b[0;32m---> 43\u001b[0m     current_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - zeroes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzeroes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - search_threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_tresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_f1 \u001b[38;5;241m>\u001b[39m best_f1:\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1271\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1092\u001b[0m     {\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1119\u001b[0m ):\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1463\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1284\u001b[0m     {\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1313\u001b[0m ):\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1767\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m \n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1767\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1539\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1539\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     96\u001b[0m             type_true, type_pred\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "predicted_labels = (scores > threshold).astype(int)\n",
    "best_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "\n",
    "print(best_f1)\n",
    "\n",
    "best_zeroes_to_fill = 0\n",
    "best_thresh = 0\n",
    "best_part_tresh = 0\n",
    "\n",
    "def optimize_zeroes_to_fill(scores, res, zeroes_to_fill, best_f1, best_thresh, true_labels):\n",
    "    for thresh_search in np.arange(0.35, 0.7, 0.01):\n",
    "        adjusted_predictions = scores.copy()\n",
    "        last_path = None\n",
    "        zero_count = 0\n",
    "        for i in range(len(res)):\n",
    "            current_path = res[\"general_path\"].iloc[i]\n",
    "\n",
    "            if last_path != current_path:\n",
    "                zero_count = 0\n",
    "                last_path = current_path\n",
    "\n",
    "            if adjusted_predictions[i] < thresh_search:\n",
    "                zero_count += 1\n",
    "            else:\n",
    "                if zero_count > 0 and zero_count <= zeroes_to_fill:\n",
    "                    adjusted_predictions[i - zero_count : i] = 1\n",
    "                zero_count = 0  \n",
    "\n",
    "        new_predictions = (scores > threshold).astype(int)\n",
    "        f1 = f1_score(true_labels, new_predictions, average=average)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh_search\n",
    "\n",
    "    return adjusted_predictions, best_thresh\n",
    "\n",
    "for cur_tresh in np.arange(0.35, 0.7, 0.01):\n",
    "\n",
    "    for zeroes in range(1, 50):  \n",
    "        new_predictions, tresh = optimize_zeroes_to_fill(scores, res, zeroes, best_f1, best_thresh=best_part_tresh, true_labels=true_labels)\n",
    "        current_f1 = f1_score(true_labels, new_predictions, average=average)\n",
    "\n",
    "        print(f\"f1: {current_f1} - zeroes: {zeroes} - search_threshold: {best_thresh} - threshold: {cur_tresh}\")\n",
    "\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_zeroes_to_fill = zeroes\n",
    "            best_part_tresh = tresh\n",
    "            best_thresh = cur_tresh\n",
    "\n",
    "    final_predictions = optimize_zeroes_to_fill(res, best_zeroes_to_fill)\n",
    "\n",
    "print(f\"Optimal zeroes_to_fill: {best_zeroes_to_fill}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal sigma: 3.7999999999999994\n",
      "Maximized F1-Score: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# Gaussian smoothing filter function using scipy's gaussian_filter1d\n",
    "def gaussian_smoothing_filter(data, sigma):\n",
    "    return gaussian_filter1d(data.astype(float), sigma=sigma)\n",
    "\n",
    "# Initialize variables for parameter optimization\n",
    "best_f1 = 0\n",
    "best_sigma = None\n",
    "\n",
    "# Loop over possible sigma values (e.g., from 0.5 to 5.0 with step 0.5)\n",
    "for sigma in np.arange(0.5, 5.5, 0.1):\n",
    "    # Apply the Gaussian smoothing filter with the current sigma\n",
    "    smoothed_scores = gaussian_smoothing_filter(scores, sigma)\n",
    "    \n",
    "    # Apply the fixed threshold to obtain binary predictions\n",
    "    predicted_labels = (smoothed_scores >= threshold).astype(int)\n",
    "    \n",
    "    # Compute the F1-score using the specified averaging method\n",
    "    current_f1 = f1_score(true_labels, predicted_labels, average=average)\n",
    "    \n",
    "    # Update the best F1-score and corresponding sigma if improvement is found\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_sigma = sigma\n",
    "\n",
    "# Apply the smoothing filter with the optimal sigma for final predictions\n",
    "final_smoothed_scores = gaussian_smoothing_filter(scores, best_sigma)\n",
    "final_predictions = (final_smoothed_scores >= thres).astype(int)\n",
    "\n",
    "# Print the optimal sigma and the maximized F1-score\n",
    "print(f\"Optimal sigma: {best_sigma}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m aggressiveness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Optimize gap filling to maximize F1 while trying to approach the target segment length of 112.2 samples\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m optimal_gap, final_predictions, best_f1, avg_diff \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_gap_filling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m112.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggressiveness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggressiveness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gap_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     82\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m final_avg_length \u001b[38;5;241m=\u001b[39m average_segment_length(final_predictions)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Print the optimal gap parameter, maximized F1-score, and average segment length details\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[66], line 57\u001b[0m, in \u001b[0;36moptimize_gap_filling\u001b[0;34m(binary_array, true_labels, target_length, aggressiveness, max_gap_search, average_method)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Search candidate gap sizes from 1 up to (max_gap_search * aggressiveness)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gap \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(max_gap_search \u001b[38;5;241m*\u001b[39m aggressiveness) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 57\u001b[0m     filled \u001b[38;5;241m=\u001b[39m \u001b[43mfill_short_gaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     avg_len \u001b[38;5;241m=\u001b[39m average_segment_length(filled)\n\u001b[1;32m     59\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(avg_len \u001b[38;5;241m-\u001b[39m target_length)\n",
      "Cell \u001b[0;32mIn[66], line 15\u001b[0m, in \u001b[0;36mfill_short_gaps\u001b[0;34m(binary_array, max_gap)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filled[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     start \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m n \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mfilled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     gap_length \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/pandas/core/series.py:1097\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1096\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[0;32m-> 1097\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_if_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[1;32m   1100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mor\u001b[39;00m warn_copy_on_write():\n",
      "File \u001b[0;32m/home/j0kr0017/conda/lib/python3.12/site-packages/pandas/core/common.py:372\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# everything failed (probably because the argument\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# wasn't actually callable); we return None\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# instead of the empty string in this case to allow\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# distinguishing between no name and a name of ''\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_if_callable\u001b[39m(maybe_callable, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    Evaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    otherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial binary prediction based on the threshold\n",
    "initial_pred = (scores >= threshold).astype(int)\n",
    "\n",
    "def fill_short_gaps(binary_array, max_gap):\n",
    "    \"\"\"\n",
    "    Fill gaps (zeros) that are surrounded by ones if the gap length is\n",
    "    less than or equal to max_gap.\n",
    "    \"\"\"\n",
    "    filled = binary_array.copy()\n",
    "    n = len(filled)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if filled[i] == 0:\n",
    "            start = i\n",
    "            while i < n and filled[i] == 0:\n",
    "                i += 1\n",
    "            gap_length = i - start\n",
    "            # Only fill if gap is short and flanked by ones\n",
    "            if start > 0 and i < n and gap_length <= max_gap:\n",
    "                filled[start:i] = 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return filled\n",
    "\n",
    "def average_segment_length(binary_array):\n",
    "    \"\"\"\n",
    "    Calculate the average length of contiguous segments where the value is 1.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    count = 0\n",
    "    for value in binary_array:\n",
    "        if value == 1:\n",
    "            count += 1\n",
    "        elif count > 0:\n",
    "            segments.append(count)\n",
    "            count = 0\n",
    "    if count > 0:\n",
    "        segments.append(count)\n",
    "    return np.mean(segments) if segments else 0\n",
    "\n",
    "def optimize_gap_filling(binary_array, true_labels, target_length=112.2,\n",
    "                         aggressiveness=1.0, max_gap_search=50, average_method='weighted'):\n",
    "    \"\"\"\n",
    "    Optimize the maximum gap length parameter that:\n",
    "      1. Adjusts the average segment length toward target_length.\n",
    "      2. Maximizes the F1-score (comparing the filled binary prediction with true_labels).\n",
    "\n",
    "    The aggressiveness parameter scales the search range for max_gap.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_gap = None\n",
    "    best_filled = binary_array.copy()\n",
    "    best_avg_diff = None\n",
    "\n",
    "    # Search candidate gap sizes from 1 up to (max_gap_search * aggressiveness)\n",
    "    for gap in range(1, int(max_gap_search * aggressiveness) + 1):\n",
    "        filled = fill_short_gaps(binary_array, gap)\n",
    "        avg_len = average_segment_length(filled)\n",
    "        diff = abs(avg_len - target_length)\n",
    "        current_f1 = f1_score(true_labels, filled, average=average_method)\n",
    "\n",
    "        # Primary objective: maximize F1-score.\n",
    "        # (We also report the difference from the target average length.)\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_gap = gap\n",
    "            best_filled = filled.copy()\n",
    "            best_avg_diff = diff\n",
    "\n",
    "    return best_gap, best_filled, best_f1, best_avg_diff\n",
    "\n",
    "# Set the aggressiveness parameter (higher -> more aggressive gap filling, testing larger gaps)\n",
    "aggressiveness = 1.0 * 20\n",
    "\n",
    "# Optimize gap filling to maximize F1 while trying to approach the target segment length of 112.2 samples\n",
    "optimal_gap, final_predictions, best_f1, avg_diff = optimize_gap_filling(\n",
    "    initial_pred, true_labels,\n",
    "    target_length=112.2,\n",
    "    aggressiveness=aggressiveness,\n",
    "    max_gap_search=75,\n",
    "    average_method=\"weighted\"\n",
    ")\n",
    "\n",
    "final_avg_length = average_segment_length(final_predictions)\n",
    "\n",
    "# Print the optimal gap parameter, maximized F1-score, and average segment length details\n",
    "print(f\"Optimal gap to fill (max_gap): {optimal_gap}\")\n",
    "print(f\"Maximized F1-Score: {best_f1:.4f}\")\n",
    "print(f\"Final average segment length: {final_avg_length:.2f} samples\")\n",
    "print(f\"Difference from target average length (112.2): {avg_diff:.2f} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal gap parameter (max_gap): 66\n",
      "Maximized F1 Score: 0.3549\n"
     ]
    }
   ],
   "source": [
    "initial_predictions = (scores >= threshold).astype(int)\n",
    "\n",
    "def fill_short_gaps(binary_array, max_gap):\n",
    "    \"\"\"\n",
    "    Fills short gaps (consecutive zeros) in a binary array.\n",
    "    A gap is filled if its length is less than or equal to max_gap and is flanked by ones.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_array: numpy array of binary values (0 or 1)\n",
    "        max_gap: maximum gap length to fill\n",
    "        \n",
    "    Returns:\n",
    "        A new binary array with short gaps filled.\n",
    "    \"\"\"\n",
    "    filled = binary_array.copy()\n",
    "    n = len(filled)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if filled[i] == 0:\n",
    "            start = i\n",
    "            # Count the length of the zero gap\n",
    "            while i < n and filled[i] == 0:\n",
    "                i += 1\n",
    "            gap_length = i - start\n",
    "            # Fill the gap if it is flanked by ones and is small enough\n",
    "            if start > 0 and i < n and gap_length <= max_gap:\n",
    "                filled[start:i] = 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return filled\n",
    "\n",
    "# Optimization loop: find the candidate max_gap that maximizes the F1 score.\n",
    "best_f1 = 0\n",
    "best_gap = None\n",
    "best_filled_predictions = initial_predictions.copy()\n",
    "\n",
    "# Try candidate gap values from 1 up to 50 (adjust range as needed)\n",
    "for candidate_gap in range(1, 100):\n",
    "    filled_predictions = fill_short_gaps(initial_predictions, candidate_gap)\n",
    "    current_f1 = f1_score(true_labels, filled_predictions)\n",
    "    \n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_gap = candidate_gap\n",
    "        best_filled_predictions = filled_predictions.copy()\n",
    "\n",
    "# Print the optimal gap parameter and the maximized F1 score\n",
    "print(f\"Optimal gap parameter (max_gap): {best_gap}\")\n",
    "print(f\"Maximized F1 Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
